# Default values for assemblyline.

coreVersion: '4.0.0.dev191'
uiVersion:   '4.0.0.dev135'
sapiVersion:   '4.0.0.dev95'

storage:
  filestore: default
  redis: default

domain: localhost
maxBodySize: 100M

tlsSecretName: ''

autoInstallServices:
  - apkaye
  - metapeek
  - metadefender
  - characterize
  - extract
  - virustotal-dynamic
  - virustotal-static

autoInstallLegacyServices:
  - pdfid
  - peepdf
  - unpacker
  - cleaver
  - espresso
  - frankenstrings
  - iparse
  - pefile
  - pixaxe
  - swiffer
  - torrentslicer
  - yara


serviceNamespace: null  # Will be {{ .Release.Name }}-services if not defined



elasticPassword: "Ch@ngeTh!sPa33w0rd"
loggingPassword: "Ch@ngeTh!sPa33w0rd"
notebookPassword: "Ch@ngeTh!sPa33w0rd"
filestorePassword: "Ch@ngeTh!sPa33w0rd"  # URL encoded version of the secretKey in the block below

filestore:
  fullnameOverride: "filestore"
  replicas: 1
  accessKey: "al_filestore"
  secretKey: "Ch@ngeTh!sPa33w0rd"
  priorityClassName: 'al-infra'


datastore:
  clusterName: "datastore"
  replicas: 3
  extraEnvs:
    - name: ELASTIC_USERNAME
      value: elastic
    - name: ELASTIC_PASSWORD
      valueFrom:
        secretKeyRef:
          name: system-passwords
          key: datastore-password
  labels:
    section: core
    component: datastore
  esJavaOpts: '-Xms6g -Xmx6g'
  esConfig:
    elasticsearch.yml: |
      logger.level=WARN
  resources:
    requests:
      cpu: 1
      memory: 12Gi
    limits:
      cpu: 6
      memory: 12Gi
  volumeClaimTemplate:
    accessModes: [ "ReadWriteOnce" ]
    storageClassName: default
    resources:
      requests:
        storage: 500Gi
  priorityClassName: 'al-infra'


logging-datastore:
  clusterName: "logging-datastore"
  replicas: 1
  extraEnvs:
  - name: ELASTIC_USERNAME
    value: elastic
  - name: ELASTIC_PASSWORD
    valueFrom:
      secretKeyRef:
        name: system-passwords
        key: logging-password
  labels:
    section: core
    component: logging-datastore
  esJavaOpts: '-Xms6g -Xmx6g'
  esConfig:
    elasticsearch.yml: |
      logger.level=WARN
  resources:
    requests:
      cpu: 1
      memory: 12Gi
    limits:
      cpu: 6
      memory: 12Gi
  volumeClaimTemplate:
    accessModes: [ "ReadWriteOnce" ]
    storageClassName: default
    resources:
      requests:
        storage: 500Gi
  priorityClassName: 'al-infra'

filebeat:
  extraEnvs:
    - name: ELASTICSEARCH_HOSTS
      value: 'logging-datastore-master'
    - name: ELASTICSEARCH_USERNAME
      value: elastic
    - name: ELASTICSEARCH_PASSWORD
      valueFrom:
        secretKeyRef:
          name: system-passwords
          key: logging-password
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  filebeatConfig:
    filebeat.yml: |-
      logging:
        level: warning
        json: true
      name: ${NODE_NAME}

      filebeat.inputs:
        - type: container
          format: docker
          paths:
            - '/var/lib/docker/containers/*/*.log'
          stream: "all"
          json:
            keys_under_root: true
            message_key: message
            ignore_decoding_error: true
          processors:
            - rename:
                fields:
                  - from: "error"
                    to: "error.message"
                ignore_missing: true
            - script:
                lang: javascript
                id: log_level
                source: >
                  function process(event) {
                      var value = event.Get("log.level");
                      if (value === null){
                        value = "INFO"
                      }
                      else if (value.toLowerCase() == "warn"){
                        value = "WARNING"
                      }
                      else if (value.toLowerCase() == "err"){
                        value = "ERROR"
                      }
                      event.Put("log.level", value.toUpperCase());
                  }

      processors:
        - add_cloud_metadata: ~
        - add_host_metadata: ~
        - add_docker_metadata: ~
        - add_kubernetes_metadata: ~
        - drop_event:
            when:
              regexp:
                container.labels.io_kubernetes_container_name: "(nginx-ingress-controller)|(tunnel-front)"

      output.elasticsearch:
        hosts: ['${ELASTICSEARCH_HOSTS:elasticsearch}:${ELASTICSEARCH_PORT:9200}']
        username: ${ELASTICSEARCH_USERNAME}
        password: ${ELASTICSEARCH_PASSWORD}

      setup.template.settings:
        index.number_of_shards: 1
        index.number_of_replicas: 0
      setup.ilm:
        enabled: true
        policy_file: /usr/share/filebeat/filebeat_policy.json
    filebeat_policy.json: |-
      {
        "policy": {
          "phases": {
            "hot": {
              "min_age": "0ms",
              "actions": {
                "rollover": {
                  "max_age": "1d",
                  "max_size": "20gb"
                },
                "set_priority": {
                  "priority": 100
                }
              }
            },
            "warm": {
              "actions": {
                "readonly": {},
                "set_priority": {
                  "priority": 50
                }
              }
            },
            "delete": {
              "min_age": "3d",
              "actions": {
                "delete": {}
              }
            }
          }
        }
      }

metricbeat:
  extraEnvs:
    - name: ELASTICSEARCH_HOSTS
      value: 'logging-datastore-master'
    - name: ELASTICSEARCH_USERNAME
      value: elastic
    - name: ELASTICSEARCH_PASSWORD
      valueFrom:
        secretKeyRef:
          name: system-passwords
          key: logging-password
  metricbeatConfig:
    # Configuration on the daemonset
    metricbeat.yml: |
      logging:
        level: warning
        json: true
      name: ${NODE_NAME}

      metricbeat.modules:
        - module: system
          period: 10s
          metricsets:
            - cpu
            - load
            - memory
            - network
            - process
            - process_summary
            - uptime
            - socket_summary
            - socket
          processes: ['.*']
          cpu.metrics:  ["percentages"]
          core.metrics: ["percentages"]
          process.include_top_n:
            by_cpu: 5      # include top 5 processes by CPU
            by_memory: 5   # include top 5 processes by memory
        - module: system
          period: 1m
          metricsets:
            - diskio
            - fsstat
        - module: docker
          metricsets:
            - "container"
            - "cpu"
            - "diskio"
            - "event"
            - "healthcheck"
            - "info"
            - "memory"
            - "network"
          hosts: ["unix:///var/run/docker.sock"]
          period: 10s
          enabled: true
          processors:
            - add_docker_metadata: ~
        - module: kubernetes
          metricsets:
            - node
            - system
            - pod
            - container
            - volume
          period: 10s
          host: ${NODE_NAME}
          hosts: ["localhost:10255"]

      processors:
        - add_cloud_metadata: ~

      output.elasticsearch:
        hosts: ['logging-datastore-master:9200']
        username: ${ELASTICSEARCH_USERNAME}
        password: ${ELASTICSEARCH_PASSWORD}

      setup.template.settings:
        index.number_of_shards: 1
        index.number_of_replicas: 0
      setup.ilm:
        enabled: true
        policy_file: /usr/share/metricbeat/metricbeat_policy.json
    # Configuration on the deployment
    kube-state-metrics-metricbeat.yml: |
      logging:
        level: warning
        json: true
      #name: ${NODE_NAME}

      metricbeat.modules:
        - module: redis
          metricsets:
            - "info"
            - "keyspace"
          period: 10s
          hosts: ["redis-volatile:6379"]
        - module: redis
          metricsets:
            - "info"
            - "keyspace"
          period: 10s
          hosts: ["redis-persistent:6379"]

      processors:
        - add_cloud_metadata: ~

      output.elasticsearch:
        hosts: ["logging-datastore-master:9200"]
        username: ${ELASTICSEARCH_USERNAME}
        password: ${ELASTICSEARCH_PASSWORD}

      setup.template.settings:
        index.number_of_shards: 1
        index.number_of_replicas: 0
      setup.ilm:
        enabled: true
        policy_file: /usr/share/metricbeat/metricbeat_policy.json

    metricbeat_policy.json: |-
      {
        "policy": {
          "phases": {
            "hot": {
              "min_age": "0ms",
              "actions": {
                "rollover": {
                  "max_age": "1d",
                  "max_size": "5gb"
                },
                "set_priority": {
                  "priority": 100
                }
              }
            },
            "warm": {
              "actions": {
                "readonly": {},
                "set_priority": {
                  "priority": 50
                }
              }
            },
            "delete": {
              "min_age": "4d",
              "actions": {
                "delete": {}
              }
            }
          }
        }
      }

kibana:
  fullnameOverride: kibana
  elasticsearchHosts: http://logging-datastore-master:9200
  healthCheckPath: /kibana/app/kibana
  extraEnvs:
    - name: SERVER_NAME
      value: localhost
    - name: ELASTICSEARCH_USERNAME
      value: elastic
    - name: ELASTICSEARCH_PASSWORD
      valueFrom:
        secretKeyRef:
          name: system-passwords
          key: logging-password
    - name: SERVER_BASEPATH
      value: /kibana
    - name: SERVER_REWRITEBASEPATH
      value: "true"
    - name: LOGGING_QUIET
      value: "true"
  priorityClassName: al-core-priority

